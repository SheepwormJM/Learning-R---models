# Using a GLMM to model FECs

library(lme4)

fe<-read.table("fake_eggs.txt", header=T)
summary(fe)

names(fe)
[1] "Region" "FEC"    "Season" "Farm"   "Rain" 

# The FEC is the outcome variable (goes on the left of the model equation)
# The Season, Region and Rain are variables, as is the Farm
# However, the Farm (and possibly also the region?) have random effects - could be included in a Mixed effects model.

# To fit a GLM using MASS:

> library(MASS)
> 
> nb1<- glm.nb(FEC~Season, data=fe)
> summary(nb1)

# To fit a GLMM for negative binomial data using lme4:

require("MASS")
glmmnb1 <- glmer.nb(FEC ~ Season  + (1|Farm), data=fe)
glmmnb1

glmmnb2 <- glmer.nb(FEC ~ Rain  + (1|Farm), data=fe)
glmmnb2

glmmnb2b <- glmer.nb(FEC ~ Raing  + (1|Farm), data=fe)
glmmnb2b

glmmnb3 <- glmer.nb(FEC ~ Rain +Season + (1|Farm), data=fe)
glmmnb3

glmmnb4 <- glmer.nb(FEC ~ Season + (1|Region), data=fe)
glmmnb4 

glmmnb5 <- glmer.nb(FEC ~ Rain + (1|Region), data=fe)
glmmnb5 

glmmnb5b <- glmer.nb(FEC ~ Raing + (1|Region), data=fe)
glmmnb5b 

glmmnb6 <- glmer.nb(FEC ~ Rain +Season + (1|Region), data=fe)
glmmnb6 

glmmnb7 <- glmer.nb(FEC ~ Rain +Season + (1|Region) + (1|Farm), data=fe)
glmmnb7

glmmnb8 <- glmer.nb(FEC ~ Rain +Season + Region +(1|Region) + (1|Farm), data=fe)
glmmnb8

library(DHARMa)
simulationOutput1 <- simulateResiduals(fittedModel = glmmnb1, n = 250)
plot(simulationOutput1)
simulationOutput2 <- simulateResiduals(fittedModel = glmmnb2, n = 250)
plot(simulationOutput2)
simulationOutput3 <- simulateResiduals(fittedModel = glmmnb3, n = 250)
plot(simulationOutput3)
simulationOutput4 <- simulateResiduals(fittedModel = glmmnb4, n = 250)
plot(simulationOutput4)
simulationOutput5 <- simulateResiduals(fittedModel = glmmnb5, n = 250)
plot(simulationOutput5)
simulationOutput6 <- simulateResiduals(fittedModel = glmmnb6, n = 250)
plot(simulationOutput6)
simulationOutput7 <- simulateResiduals(fittedModel = glmmnb7, n = 250)
plot(simulationOutput7)
simulationOutput8 <- simulateResiduals(fittedModel = glmmnb8, n = 250)
plot(simulationOutput8)

# to try to compare glm.nb with glmer.nb:
# To plot FEC ~ Raing:

library(ggplot2)
library(viridis)
library(DHARMa)
library(MASS)
library(lme4)

x<-ggplot(data=fe, aes(x=Raing, y=FEC))+
    labs(y="FEC", x="Rain group") +
    geom_boxplot(mapping=aes(x=Raing, y=FEC, fill=Season, colour=Region), outlier.shape=NA, size=1)+ scale_fill_viridis(discrete=TRUE) + scale_colour_viridis(discrete=TRUE)
x

## Hmmm, so the Raing is not being seen in the correct order - <20, >40, 20-30, 30-40. 
# To re-order can do:
fe_ordered<-ordered(fe$Raing, levels = c("<20", "20-30", "30-40", ">40"))
fe$Raingord<-fe_ordered
class(fe$Raingord)
# "ordered" "factor"

# Try re-plotting:
x<-ggplot(data=fe, aes(x=Raingord, y=FEC))+
    labs(y="FEC", x="Rain group") +
    geom_boxplot(mapping=aes(x=Raingord, y=FEC, fill=Season, colour=Region), outlier.shape=NA, size=1)+ scale_fill_viridis(discrete=TRUE) + scale_colour_viridis(discrete=TRUE)
x
# Good.

# Try a glm.nb for FEC ~ Rain group
nb1<- glm.nb(FEC~Raingord, data=fe)
nb1
simulationOutput <- simulateResiduals(fittedModel = nb1, n = 250)
plot(simulationOutput)

# Now it calls the raingord by .L, .Q and .C. Not quite sure what these are... 

# To try with unordered:
nb2<- glm.nb(FEC~Raing, data=fe)
nb2
simulationOutput <- simulateResiduals(fittedModel = nb2, n = 250)
plot(simulationOutput)

# It looks like the output is slightly different but hte model is essentially the same. 
# DHARMa output the same.

# To try with random effects of farm:

glmmnb1 <- glmer.nb(FEC ~ Raing  + (1|Farm), data=fe)
glmmnb1
simulationOutput <- simulateResiduals(fittedModel = glmmnb1, n = 250)
plot(simulationOutput)

glmmnb2 <- glmer.nb(FEC ~ Raingord  + (1|Farm), data=fe)
glmmnb2
simulationOutput <- simulateResiduals(fittedModel = glmmnb2, n = 250)
plot(simulationOutput)

# Not a huge difference, but the models do run. Can see there is variance by farm in the model fit.

glmmnbx <- glmer.nb(FEC ~ Raingord  + Season + (1|Farm) + (1|Region), data=fe)
glmmnbx
simulationOutput <- simulateResiduals(fittedModel = glmmnbx, n = 250)
plot(simulationOutput)

# There doesn't seem to be much difference between this and the glm.nb model run with MASS! If anything, it might be worse! 

# Checked fit using DHARMa and very little difference. 

> library(DHARMa)
> simulationOutput <- simulateResiduals(fittedModel = glmmnb1, n = 250)
> plot(simulationOutput)
> simulationOutput <- simulateResiduals(fittedModel = nb1, n = 250)
> plot(simulationOutput)

#####################################################################################################################################
###################################### Other models ##############################################################################




##############################################################################################################################
######################################## Zero-inflated? #####################################################################

# If you need to then see here: 

#############################################################################################################################
###################################### Issues ############################################################################

# isSingular

# Singular models: random effect variances estimated as zero, or correlations estimated as +/- 1

# It is very common for overfitted mixed models to result in singular fits. Technically, singularity means that some of 
# the θ (variance-covariance Cholesky decomposition) parameters corresponding to diagonal elements of the Cholesky factor 
# are exactly zero, which is the edge of the feasible space, or equivalently that the variance-covariance matrix has some 
# zero eigenvalues (i.e. is positive semidefinite rather than positive definite), or (almost equivalently) that some of 
# the variances are estimated as zero or some of the correlations are estimated as +/-1. This commonly occurs in two scenarios:

# 1. small numbers of random-effect levels (e.g. <5), as illustrated in these simulations and discussed (in a somewhat 
# different, Bayesian context) by Gelman (2006).
# 
# 2. complex random-effects models, e.g. models of the form (f|g) where f is a categorical variable with a relatively 
# large number of levels, or models with several different random-slopes terms.

# When using lme4, singularity is most obviously detectable in the output of summary.merMod() or VarCorr.merMod() when a 
# variance is estimated as 0 (or very small, i.e. orders of magnitude smaller than other variance components) or when a
# correlation is estimated as exactly ±1. However, as pointed out by D. Bates, Kliegl, et al. (2015), singularities in 
# larger variance-covariance matrices can be hard to detect: checking for small values among the diagonal elements of 
# the Cholesky factor is a good start.

theta <- getME(model,"theta")
## diagonal elements are identifiable because they are fitted
##  with a lower bound of zero ...
diag.element <- getME(model,"lower")==0
any(theta[diag.element]<1e-5)
# As of lme4 version 1.1-19, this functionality is available as isSingular(model). - In MCMCglmm, singular or near-singular 
# models will provoke an error and a requirement to specify a stronger prior.

# At present there are a variety of strong opinions about how to resolve such problems. Briefly:

# Barr et al. (2013) suggest always starting with the maximal model (i.e. the most random-effects component of the model that is
# theoretically identifiable given the experimental design) and then dropping terms when singularity or non-convergence occurs (please 
# see the paper for detailed recommendations …)
# 
#  Matuschek et al. (2017) and D. Bates, Kliegl, et al. (2015) strongly disagree, suggesting that models should be simplified a priori 
# whenever possible; they also provide tools for diagnosing and mitigating singularity.
# One alternative (suggested by Robert LaBudde) for the small-numbers-of-levels scenario is to “fit the model with the random factor as 
# a fixed effect, get the level coefficients in the sum to zero form, and then compute the standard deviation of the coefficients.” This 
# is appropriate for users who are (a) primarily interested in measuring variation (i.e. the random effects are not just nuisance 
# parameters, and the variability [rather than the estimated values for each level] is of scientific interest), (b) unable or unwilling 
# to use other approaches (e.g. MCMC with half-Cauchy priors in WinBUGS), (c) unable or unwilling to collect more data. For the simplest 
# case (balanced, orthogonal, nested designs with normal errors) these estimates of standard deviations should equal the classical 
# method-of-moments estimates.
#
# Bayesian approaches allow the user to specify a informative prior that avoids singularity.
# The blme package (Chung et al. 2013) provides a wrapper for the lme4 machinery that adds a particular form of weak prior to get an 
# approximate a Bayesian maximum a posteriori estimate that avoids singularity.
# The MCMCglmm package allows for priors on the variance-covariance matrix
# The rstanarm and brms packages provide wrappers for the Stan Hamiltonian MCMC engine that fit GLMMs via lme4 syntax, again allowing a 
# variety of priors to be set.

# If a variance component is zero, dropping it from the model will have no effect on any of the estimated quantities (although it will 
# affect the AIC, as the variance parameter is counted even though it has no effect). Pasch, Bolker, and Phelps (2013) gives one example 
# where random effects were dropped because the variance components were consistently estimated as zero. Conversely, if one chooses for 
# philosophical grounds to retain these parameters, it won’t change any of the answers.

